{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow: Basic Turorial ",
      "provenance": [],
      "collapsed_sections": [
        "V0LEPuS-TOaY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf0VpUOnZyNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6RhxyVeZ0go",
        "colab_type": "code",
        "outputId": "d83a4c66-26b0-4ece-b451-3142ddccf40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkMojgTJXM8Z",
        "colab_type": "text"
      },
      "source": [
        "### 1) Creating and Running a Session\n",
        "The first thing we should learn about Tensorflow is that is does not interpret the code line by line. It uses a uses a special funtion to run all the operations. This function is called tf.Session().                        \n",
        "A session allows to execute graphs or part of graphs (seen later in this notebook)                      \n",
        "It allocates resources (on one or more machines) for that and holds the actual values of intermediate results and variables.       \n",
        "The execution itself is then done with the .run() method of the Session object.\n",
        "When called, this method completes one set of computations in our graph in the following manner: *it starts at the requested output(s) and then works backword, computing nodes that must be executed according to the set of dependencies.*\n",
        "\n",
        "The following is the code snippet of how Session() is used:                \n",
        "sess = tf.Sesssion()                                                  \n",
        "sess.run(inputs)                                                  \n",
        "sess.close()       \n",
        "\n",
        "(OR)              \n",
        "\n",
        "with tf.Session() as sess:                                             \n",
        "\n",
        "The second one is recommended as we dont have to close the session explicitly.\n",
        "\n",
        "Its okay if you didn't get a clear idea about how Session() works, you will see the use to Session in every code snippet below, and thus it will be clear to you...                  \n",
        " ## Go Ahead \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEhCjy3XbHuF",
        "colab_type": "text"
      },
      "source": [
        "## 2) Basic Maths Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kXhxOTHZ8Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declaring Constants in Tensowflow \n",
        "\n",
        "x1 = tf.constant(5)   # x1=5\n",
        "x2 = tf.constant(6)   # x1=6\n",
        "x3 = tf.constant(-18.0) # x3=-18"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2N2-eYkaAdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#result = x1*x2    This will also work\n",
        "addd = tf.add(x1,x2, name=\"addd\")                   # Adds the tensors, req. parameters:2\n",
        "subb = tf.subtract(x1,x2, name=\"subb\")              # Subtracts the tensors, req. parameters:2\n",
        "multiplyy = tf.multiply(x1,x2, name=\"multiplyy\")    # Multiply the tensors, req. parameters:2\n",
        "didd = tf.divide(x1,x2, name=\"didd\")                # Divides the tensors, req. parameters:2\n",
        "addmull =  tf.add_n([x1,x2], name=\"addmull\")        # Adds multiple Tensors of similar data types\n",
        "modd = tf.math.floormod(x2,x1, name=\"modd\")         # Performs the modulo operation on similar datatype tensors ,floor(x / y) * y + mod(x, y) = x.\n",
        "abss = tf.abs(x3, name=\"abss\")                      # Computes the absolute value\n",
        "negativee = tf.negative(x3, name=\"negativee\")       # Negates the tensor\n",
        "signn = tf.sign(x3, name=\"signn\")                   # Extracts the sign from the tensor. 1 if positive and -1 if negative\n",
        "signn1 = tf.sign(x1, name=\"signn\")   \n",
        "reciprocall = tf.reciprocal(x1, name=\"reciprocall\") # Computes the reciprocals\n",
        "# This creates a tensor and will not process anything will a session is run "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyDwLfedaCpc",
        "colab_type": "code",
        "outputId": "0fdc2355-c8db-400c-f5d9-ce6b425a86ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# So, to see the result, we run it in a session\n",
        "sess = tf.Session()\n",
        "print(sess.run(addd))\n",
        "print(sess.run(subb))\n",
        "print(sess.run(multiplyy))\n",
        "print(sess.run(didd))\n",
        "print(sess.run(addmull))\n",
        "print(sess.run(modd))\n",
        "print(sess.run(abss))\n",
        "print(sess.run(negativee))\n",
        "print(sess.run(signn))\n",
        "print(sess.run(signn1))\n",
        "#print(sess.run(reciprocall))\n",
        "sess.close()\n",
        "#graph = tf.get_default_graph()\n",
        "#print(graph.get_operations())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n",
            "-1\n",
            "30\n",
            "0.8333333333333334\n",
            "11\n",
            "1\n",
            "18.0\n",
            "18.0\n",
            "-1.0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQPtCUW-bQ5U",
        "colab_type": "text"
      },
      "source": [
        "## 3) Rounding and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Bp-aGobgsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x4 = tf.constant([-6.5, -3.5, 3.5, 6.5])\n",
        "x5 = tf.constant([[1,3],[7,2]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTX-_IEvbo_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roundd = tf.round(x3, name=\"roundd\")   # Round to the nearest integer. Req. Parameters:1\n",
        "rintt = tf.rint(x3, name=\"rintt\")      # Round to the nearest integer, round to even if there are two nearest integer. Req. Parameters:1\n",
        "ceill = tf.ceil(x3, name=\"ceill\")      # Returns the smallest integer greater than the value. Req. Parameters:1\n",
        "floorr = tf.ceil(x3, name=\"floorr\")    # Returns the greatest integer smaller than the value. Req. Parameters:1\n",
        "maximumm = tf.maximum(x1,x2, name=\"maximumm\")   # Returns the maximum tensor among the input tensors. Req. Parameters:2\n",
        "minimumm = tf.minimum(x1,x2, name=\"minimumm\")   # Returns the minimum tensor among the input tensors Req. Parameters:2\n",
        "argmaxx = tf.argmax(x4, name=\"argmaxx\")      # Returns the index of max element. Req. Parameters:1\n",
        "argminn = tf.argmin(x4, name=\"argminn\")      # Returns the index of min element. Req. Parameters:1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKdruae0bsg3",
        "colab_type": "code",
        "outputId": "6f303d20-f624-4fce-a839-a589db23d858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    print(sess.run(roundd))\n",
        "    print(sess.run(rintt))\n",
        "    print(sess.run(ceill))\n",
        "    print(sess.run(floorr))\n",
        "    print(sess.run(maximumm))\n",
        "    print(sess.run(minimumm))\n",
        "    print(sess.run(argmaxx))\n",
        "    print(sess.run(argminn))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-18.0\n",
            "-18.0\n",
            "-18.0\n",
            "-18.0\n",
            "6\n",
            "5\n",
            "3\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkKuMcSlbxMy",
        "colab_type": "text"
      },
      "source": [
        "## 4) Rank and Shape of a Tensor\n",
        "The rank of a tf.Tensor object is its number of dimensions. Synonyms for rank include order or degree or n-dimension. Note that rank in TensorFlow is not the same as matrix rank in mathematics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ypm8F_Eey07",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*  Rank 0 -> Scalar (Single Value)\n",
        "*  Rank 1 -> Vector (Array)\n",
        "*  Rank 2 -> Matrix (Table)\n",
        "*  Rank 3 -> 3-Tensor (cube of numbers)\n",
        "*  Rank n -> n-Tensor (you get the idea)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4WbGNCieudI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Rank 0 Tensors Examples \n",
        "mammal = tf.Variable(\"Elephant\", tf.string)\n",
        "ignition = tf.Variable(451, tf.int16)\n",
        "floating = tf.Variable(3.14159265359, tf.float64)\n",
        "its_complicated = tf.Variable(12.3 - 4.85j, tf.complex64)\n",
        "\n",
        "## Rank 1 Tensors Examples\n",
        "mystr = tf.Variable([\"Hello\"], tf.string)\n",
        "cool_numbers  = tf.Variable([3.14159, 2.71828], tf.float32)\n",
        "first_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)\n",
        "its_very_complicated = tf.Variable([12.3 - 4.85j, 7.5 - 6.23j], tf.complex64)\n",
        "\n",
        "## Rank 2 Tensors Examples \n",
        "mymat = tf.Variable([[7],[11]], tf.int16)\n",
        "myxor = tf.Variable([[False, True],[True, False]], tf.bool)\n",
        "linear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)\n",
        "squarish_squares = tf.Variable([ [4, 9], [16, 25] ], tf.int32)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Akr079qfax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "When you train a model, you use variables to hold and update parameters. Variables are in-memory buffers containing tensors. \n",
        "They must be explicitly initialized and can be saved to disk during and after training. \n",
        "You can later restore saved values to exercise or analyse the model.\n",
        "'''\n",
        "init_op = tf.initialize_all_variables()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLbI4ulvg27b",
        "colab_type": "code",
        "outputId": "591c7d0a-9b10-4a56-efa0-c446094ad5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "## tf.rank() is used to get the rank of the tensor\n",
        "sess = tf.Session()\n",
        "sess.run(init_op)\n",
        "print(sess.run(tf.rank(mammal)))\n",
        "print(sess.run(mammal))\n",
        "#print(sess.run(tf.rank(ignition)))\n",
        "#print(sess.run(tf.rank(floating)))\n",
        "#print(sess.run(tf.rank(its_complicated)))\n",
        "\n",
        "\n",
        "print(sess.run(tf.rank(mystr)))\n",
        "print(sess.run(mystr))\n",
        "#print(sess.run(tf.rank(cool_numbers)))\n",
        "#print(sess.run(tf.rank(first_primes)))\n",
        "#print(sess.run(tf.rank(its_very_complicated)))\n",
        "\n",
        "print(sess.run(tf.rank(mymat)))\n",
        "print(sess.run(mymat))\n",
        "#print(sess.run(tf.rank(myxor)))\n",
        "#print(sess.run(tf.rank(linear_squares)))\n",
        "#print(sess.run(tf.rank(squarish_squares)))\n",
        "sess.close()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "b'Elephant'\n",
            "1\n",
            "[b'Hello']\n",
            "2\n",
            "[[ 7]\n",
            " [11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnU-GbdTrC1k",
        "colab_type": "text"
      },
      "source": [
        "### Shape of a tensor\n",
        "The shape is the number of elements in each dimension, e.g.: \n",
        ", a vector has rank 1 and a shape of \n",
        "\n",
        "*   a scalar has a rank 0 and an empty shape ()\n",
        "*   a vector has rank 1 and a shape of (X)\n",
        "*   a matrix has rank 2 and a shape of (X, Y) and so on.\n",
        "\n",
        "# A tensor can have maximun of 8 dimensions.![alt text](https://www.guru99.com/images/1/080418_1250_WhatisaTens2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKhmTc22iWs4",
        "colab_type": "code",
        "outputId": "494aa73b-e331-4a53-96db-d0191f72874b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "## tf.shape() is used to get the shape of the tensor\n",
        "## RANK 0 \n",
        "x6 = tf.constant(56)  \n",
        "with tf.Session() as sess:\n",
        "  print(\"Shape of x6 :\", sess.run(tf.shape(x6)))\n",
        "  print(\"Rank of x6 is :\", sess.run(tf.rank(x6)))\n",
        "  print(sess.run(x6))\n",
        "  print(\"ITS A CONSTANT SO THE RANK AND SHAPE IS 0\")\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x6 : []\n",
            "Rank of x6 is : 0\n",
            "56\n",
            "ITS A CONSTANT SO THE RANK AND SHAPE IS 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r76eRpK9uVHE",
        "colab_type": "code",
        "outputId": "0b480447-3627-47b3-f396-59aadd5bb7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "## tf.shape() is used to get the shape of the tensor\n",
        "x7 = tf.constant([18,9])  \n",
        "with tf.Session() as sess:\n",
        "  print(\"Shape of x7:\", sess.run(tf.shape(x7)))\n",
        "  print(\"Rank of x7 is :\", sess.run(tf.rank(x7)))\n",
        "  print(sess.run(x7))\n",
        "  print(\"ITS A ARRAY WITH LENGTH 2, SO RANK IS 1 AND SHAPE(len of array) is 2\")\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x7: [2]\n",
            "Rank of x7 is : 1\n",
            "[18  9]\n",
            "ITS A ARRAY WITH LENGTH 2, SO RANK IS 1 AND SHAPE(len of array) is 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIj07syisg1o",
        "colab_type": "code",
        "outputId": "e8f0e2bb-ad3f-403c-b16b-a9ee8b5c67d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "## tf.shape() is used to get the shape of the tensor\n",
        "x8 = tf.constant([ [1, 1],        \n",
        "                   [2, 2], \n",
        "                   [3, 3], \n",
        "                  ])  \n",
        "with tf.Session() as sess:\n",
        "  print(\"Shape of x8 (Rows and columns resp):\", sess.run(tf.shape(x8)))\n",
        "  print(\"Rank of x8 is :\", sess.run(tf.rank(x8)))\n",
        "  print(sess.run(x8))\n",
        "  print(\"ITS A MATRIX IS DIMENSIONS (ROWS AND COLUMNS) 3x2, SO THE RANK IS 2 AND SHAPE IS 3X2\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x8 (Rows and columns resp): [3 2]\n",
            "Rank of x8 is : 2\n",
            "[[1 1]\n",
            " [2 2]\n",
            " [3 3]]\n",
            "ITS A MATRIX IS DIMENSIONS (ROWS AND COLUMNS) 3x2, SO THE RANK IS 2 AND SHAPE IS 3X2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0_o_zH9uW3_",
        "colab_type": "code",
        "outputId": "87e16f2e-8049-4b20-cb1b-daa339d1fcb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "## tf.shape() is used to get the shape of the tensor\n",
        "x9 = tf.constant([[[1, 1, 1, 1], \n",
        "                   [2, 2, 2, 2]], \n",
        "                  \n",
        "                  [[3, 3, 3, 3], \n",
        "                   [4, 4, 4, 4]]]) \n",
        "with tf.Session() as sess:\n",
        "  print(\"Shape of x9 (Rows and columns resp):\", sess.run(tf.shape(x9)))\n",
        "  print(\"Rank of x9 is :\", sess.run(tf.rank(x9)))\n",
        "  print(\"ITS A MULTIDIMENTIONAL ARRAY WITH RANK 3 AND SHAPE [2 2 3]\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x9 (Rows and columns resp): [2 2 4]\n",
            "Rank of x9 is : 3\n",
            "ITS A MULTIDIMENTIONAL ARRAY WITH RANK 3 AND SHAPE [2 2 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBY3bJwyxrNn",
        "colab_type": "text"
      },
      "source": [
        "## 5) Creating Tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzxP2kCAxqze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x10 = tf.constant(25)           # Creats a constant tensor whose value cannot be change. Required parameters (value)\n",
        "x11 = tf.zeros([2, 2])          # Creats a 2x2 matrix of all zeros. Required parameters (shape)\n",
        "x12 = tf.ones([3, 2])           # Creats a 3x2 matrix of all onces. Required parameters (shape)\n",
        "x13 = tf.fill([2, 3], 99)       # Creats a 2x3 matrix with all value = 99. Required parameters (shape, value)\n",
        "x14 = tf.linspace(2.,10.,5)     # Creats a tensor containing a linear range of values. It only takes float as input and returns and 1x5 dim tensor. Required parameters (start, stop, num)\n",
        "x15 = tf.range(10,50,delta=5)   # Creats a range of values with increment = value of delta, same as range in pyhton. Required parameters (start limit, delta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6ziNZaBvkDT",
        "colab_type": "code",
        "outputId": "f49ba0b7-c1a3-4dbc-de4f-93f1a20f2d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  print(\"x10: \", sess.run(x10))    \n",
        "  print(\"\")\n",
        "  print(\"x11: \",sess.run(x11))\n",
        "  print(\"\")\n",
        "  print(\"x12: \",sess.run(x12))\n",
        "  print(\"\")\n",
        "  print(\"x13: \",sess.run(x13))\n",
        "  print(\"\")\n",
        "  print(\"x14: \",sess.run(x14))\n",
        "  print(\"\")\n",
        "  print(\"x15: \",sess.run(x15))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x10:  25\n",
            "\n",
            "x11:  [[0. 0.]\n",
            " [0. 0.]]\n",
            "\n",
            "x12:  [[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n",
            "\n",
            "x13:  [[99 99 99]\n",
            " [99 99 99]]\n",
            "\n",
            "x14:  [ 2.  4.  6.  8. 10.]\n",
            "\n",
            "x15:  [10 15 20 25 30 35 40 45]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElnQyLAN1sTy",
        "colab_type": "text"
      },
      "source": [
        "## 6) Creating Tensors with random values\n",
        "Many Tensorflow applications required tensors that contain random values instead\n",
        "of predetermined values. Tensorflow thus can also create normally distributed \n",
        "values using random_normal and truncate_normal funcations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hac5LCl01sAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x16 = tf.random_normal([10], mean=0.0, stddev=1, name=\"random_normal_distribution\")\n",
        "# Random Normal funtion generates random values throughout the distribution with mean = 0 and standard diviation = 1\n",
        "# Required Parameters (shape,mean,stddev)\n",
        "\n",
        "x17 = tf.truncated_normal([10], mean=0.0, stddev=1, name=\"turncate_distribution\")\n",
        "# Truncate Normal funtion is same as random normal function except it removes the values which lies below and above two standard diviation. \n",
        "# Required Parameters (shape, mean, stddev)\n",
        "\n",
        "x18 = tf.random_uniform([10], minval=0, maxval=10, name=\"random_uniform_distribution\")\n",
        "# Creates a tensor with uniformaly distributed values between the min and max value.\n",
        "# Required Parameters (shape, minval, maxval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQRi7e0C0i1G",
        "colab_type": "code",
        "outputId": "6fa9d684-a021-4a65-836c-462d834dc3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  print(\"x16 is: \",sess.run(x16))\n",
        "  print(\"\")\n",
        "  print(\"x17 is: \", sess.run(x16))\n",
        "  print(\"\")\n",
        "  print(\"x18 is: \", sess.run(x18))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x16 is:  [-1.1461076  -0.02413565 -0.33261836 -1.3072872  -0.17628473 -0.44703802\n",
            "  0.47290906  0.03912739 -0.2437659  -0.8332586 ]\n",
            "\n",
            "x17 is:  [ 1.5817474   0.4296015   0.35490763  0.7554337  -0.11347314  0.68584996\n",
            "  0.8362397   0.9908679   0.8154049   0.8394619 ]\n",
            "\n",
            "x18 is:  [6.0906816 8.96202   1.6181362 4.1257915 3.9249694 6.6718807 8.613025\n",
            " 9.6750555 0.5791795 4.2164803]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrTc8z3S5yMG",
        "colab_type": "text"
      },
      "source": [
        "## 7) Transforming Tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Vv-ZW75x50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e5b364a2-3dc7-4ac0-c3ba-1396ca166b87"
      },
      "source": [
        "'''\n",
        "We will use the follow tensors\n",
        "x6 = tf.constant(56)                  Rank: 0, Shape: 1\n",
        "\n",
        "x7 = tf.constant([18,9])              Rank: 1, Shape: 2\n",
        "\n",
        "x8 = tf.constant([ [1, 1],            Rank: 2, Shape: [3,2]\n",
        "                   [2, 2], \n",
        "                   [3, 3], \n",
        "                  ])  \n",
        "\n",
        "x9 = tf.constant([[[1, 1, 1, 1],      Rank: 3, Shape: [2, 2, 3]\n",
        "                   [2, 2, 2, 2]], \n",
        "                  \n",
        "                  [[3, 3, 3, 3], \n",
        "                   [4, 4, 4, 4]]]) \n",
        "'''"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWe will use the follow tensors\\nx6 = tf.constant(56)                  Rank: 0, Shape: 1\\n\\nx7 = tf.constant([18,9])              Rank: 1, Shape: 2\\n\\nx8 = tf.constant([ [1, 1],            Rank: 2, Shape: [3,2]\\n                   [2, 2], \\n                   [3, 3], \\n                  ])  \\n\\nx9 = tf.constant([[[1, 1, 1, 1],      Rank: 3, Shape: [2, 2, 3]\\n                   [2, 2, 2, 2]], \\n                  \\n                  [[3, 3, 3, 3], \\n                   [4, 4, 4, 4]]]) \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Rky9o84Y5v",
        "colab_type": "code",
        "outputId": "f575809b-4366-49f6-b720-e13f26669931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  x19 = tf.cast(x6, tf.float32)           # Used to convert the data type of tensors. Req Parameter (tensor, dtype)\n",
        "  print(sess.run(x19))\n",
        "  print(\"\")\n",
        "  x20 = tf.reshape(x8, [1,6])             # Reshapes the tensors. It cannot remove any element, so it accepts the shape in which the product of the rows and columns is equal to the number of elements in the tensor.\n",
        "  print(sess.run(x20))\n",
        "  print(\"\")\n",
        "  x21 = tf.reshape(x9,[1,4,4])\n",
        "  print(sess.run(x21))\n",
        "  print(\"\")\n",
        "  x22 = tf.squeeze(x9)                    # Removes dimensions of size 1\n",
        "  print(sess.run(x22))\n",
        "  print(\"Shape of x22: \",sess.run(tf.shape(x22)))\n",
        "  print(\"\")\n",
        "  "
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56.0\n",
            "\n",
            "[[1 1 2 2 3 3]]\n",
            "\n",
            "[[[1 1 1 1]\n",
            "  [2 2 2 2]\n",
            "  [3 3 3 3]\n",
            "  [4 4 4 4]]]\n",
            "\n",
            "[[[1 1 1 1]\n",
            "  [2 2 2 2]]\n",
            "\n",
            " [[3 3 3 3]\n",
            "  [4 4 4 4]]]\n",
            "Shape of x22:  [2 2 4]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDFHwF058bZO",
        "colab_type": "code",
        "outputId": "d34fb470-7be7-40a0-b8ee-48ecee6a7637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Lets discuss tf.reverse()\n",
        "# tf.reverse() reverses given dimensions of the tensor.\n",
        "# tf.reverse() is a bit complicated, required parameters are (tensor, axis),\n",
        "# The range of the axis is [-4,4). Means -4 is included but 4 is excluded. \n",
        "x23 = [[[[ 0,  1,  2,  3],\n",
        "                  [ 4,  5,  6,  7],\n",
        "                  [ 8,  9, 10, 11]],\n",
        "                 [[12, 13, 14, 15],\n",
        "                  [16, 17, 18, 19],\n",
        "                  [20, 21, 22, 23]]]]\n",
        "with tf.Session() as sess:\n",
        "  print(\"Rank of x23 is:\", sess.run(tf.rank(x23)))\n",
        "  print(\"Shape of x23 is: \", sess.run(tf.shape(x23)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rank of x23 is: 4\n",
            "Shape of x23 is:  [1 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2ri7GRlGTeg",
        "colab_type": "code",
        "outputId": "b8ec991a-61a5-4401-ce66-ca0768924d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  x24 = tf.reverse(x23,[0])\n",
        "  print(sess.run(x24))\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 0  1  2  3]\n",
            "   [ 4  5  6  7]\n",
            "   [ 8  9 10 11]]\n",
            "\n",
            "  [[12 13 14 15]\n",
            "   [16 17 18 19]\n",
            "   [20 21 22 23]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxTdc1YxW4Sz",
        "colab_type": "code",
        "outputId": "234c0610-d390-4780-cb9f-deac88d4711d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Lets Discuss tf.slice()\n",
        "# tf.slice() extracts a protion of a tensor\n",
        "# Required Parameters are (tensor, begin, size) where begin is the location from where the slicing will start (location is accoring to matrix in maths) and \n",
        "# The slice size is represented as a tensor shape, where size[i] is the number of elements of the 'i'th dimension of input_ that you want to slice. \n",
        "\n",
        "\n",
        "x25 = tf.constant(([[[1, 1, 1], [2, 2, 2]],\n",
        "                 [[3, 3, 3], [4, 4, 4]],\n",
        "                 [[5, 5, 5], [6, 6, 6]]]))\n",
        "with tf.Session() as sess:\n",
        "  print(\"Rank of x25: \", sess.run(tf.rank(x25)))\n",
        "  print(\"Shape of x25: \", sess.run(tf.shape(x25)))\n",
        "  print(\"\")\n",
        "  print(\"Slice1: \", sess.run(tf.slice(x26, [1, 0, 0], [1, 1, 3])))\n",
        "  print(\"\")\n",
        "  print(\"Slice2: \", sess.run(tf.slice(x26,[1, 0, 0], [2, 1, 3])))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rank of x25:  3\n",
            "Shape of x25:  [3 2 3]\n",
            "\n",
            "Slice1:  [[[3 3 3]]]\n",
            "\n",
            "Slice2:  [[[3 3 3]]\n",
            "\n",
            " [[5 5 5]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXSa-iPubVVn",
        "colab_type": "code",
        "outputId": "bfd0ceb0-37f9-4091-e66d-a58161842c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Some one simple examples of slicing..\n",
        "x27 = tf.constant([26,25,24,23,22,21,20])           # Simple Array\n",
        "x28 = tf.constant([[2,1,3],[5,6,4],[8,9,7]])        # Simple 3x3 Matrix\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(tf.rank(x27)),sess.run(tf.shape(x27)))\n",
        "  print(sess.run(tf.slice(x27,[3],[4])))\n",
        "  print(\"\")\n",
        "  print(sess.run(tf.slice(x28,[1,1],[2,2])))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 [7]\n",
            "[23 22 21 20]\n",
            "\n",
            "[[6 4]\n",
            " [9 7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZZ5CIzos574",
        "colab_type": "code",
        "outputId": "94b37c16-7fd5-4c0f-9cc9-f334791f98c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Lets learn about tf.stack()\n",
        "# It combines a list of tensors into a tensor of greater rank\n",
        "'''\n",
        "Packs the list of tensors in values into a tensor with rank one higher than each tensor in values, by packing them along the axis dimension. \n",
        "Given a list of length N of tensors of shape (A, B, C);\n",
        "if axis == 0 then the output tensor will have the shape (N, A, B, C). \n",
        "if axis == 1 then the output tensor will have the shape (A, N, B, C). Etc.\n",
        "''' \n",
        "# Required parameters (tensors, axis=0)\n",
        "\n",
        "x29 = tf.constant([1,2,3], name=\"x29\")      # Rank and shape of x29,x30,x31 is 1 , [3]\n",
        "x30 = tf.constant([4,5,6], name=\"x30\")\n",
        "x31 = tf.constant([7,8,9], name=\"x31\")\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  x32 = tf.stack([x29,x30,x31], axis=0)\n",
        "  print(sess.run(x32))\n",
        "\n",
        "# Thus, axis=0 will combine them row wise and axis=1 will combine them column wise.\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ehXyyT0vqWg",
        "colab_type": "code",
        "outputId": "88f0d328-8d76-4f20-f6cf-fab303c12433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Next is obviously tf.unstack()\n",
        "# It splits a tensor into a list of tensors of lesser rank.\n",
        "# Required parameters (tensor, num=None,axis=0)\n",
        "\n",
        "'''\n",
        "Unpacks num tensors from value by chipping it along the axis dimension. \n",
        "If num is not specified (the default), it is inferred from value's shape. If value.shape[axis] is not known, ValueError is raised.\n",
        "For example, given a tensor of shape (A, B, C, D);\n",
        "If axis == 0 then the i'th tensor in output is the slice value[i, :, :, :] and each tensor in output will have shape (B, C, D). \n",
        "(Note that the dimension unpacked along is gone, unlike split).\n",
        "If axis == 1 then the i'th tensor in output is the slice value[:, i, :, :] and each tensor in output will have shape (A, C, D). Etc.\n",
        "'''\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  x33 = tf.unstack(x32,axis=0)\n",
        "  print(sess.run(x33))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([1, 2, 3], dtype=int32), array([4, 5, 6], dtype=int32), array([7, 8, 9], dtype=int32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "athUyzXgxam5",
        "colab_type": "text"
      },
      "source": [
        "## 8) Exponents and Logarithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO_6e1rWxhM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' I am just up all the functions availale to get a clear idea of what it is..\n",
        "I am not providing examples coz I believe you already have the idea as \n",
        "it is similar to that of provided in numpy\n",
        "'''\n",
        "\n",
        "# tf.square(x,name)                         Returns the square of the argument\n",
        "# tf.squared_difference(x,y,name)           Subtracts the first argument from the second and returns the square \n",
        "# sqrt(x,name)                              Returns the square root of the argument\n",
        "# rsqrt(x,name)                             Returns the reciprocal of the square root\n",
        "# pow(x,y,name)                             Returns element of the first tensor raised to the power of the element of the second tensor\n",
        "# exp(x,name)                               Returns the exponential function of the argument\n",
        "# expm1(x,name)                             Returns the exponential function of the argument minus one, exp(x) - 1\n",
        "# log(x,name)                               Returns the natural log of the argument\n",
        "# log1p(x,name)                             Return log(x+1)\n",
        "# erf(x,name)                               Returns the error function\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKyGouooz45Z",
        "colab_type": "text"
      },
      "source": [
        "## 9) Vector and Matrix Operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiihEyr8z4kN",
        "colab_type": "code",
        "outputId": "f25d98b2-73a8-4504-9de9-1ec803814a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "'''\n",
        "We will use these tensors\n",
        "x29 = tf.constant([1,2,3])      # Rank and shape of x29,x30,x31 is 1 , [3]\n",
        "x30 = tf.constant([4,5,6])\n",
        "x31 = tf.constant([7,8,9])\n",
        "'''\n",
        "x40 = tf.constant([[1,2,3],[4,5,6],[7,8,9]], name=\"x40\")      # Simple 3x3 Matrix\n",
        "x41 = tf.constant([[9,8,7],[6,5,4],[3,2,1]], name=\"x41\")      # Simple 3x3 Matrix\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "  x34 = tf.tensordot(x29,x30,1)     # Returns the sum of products for the elements in the given axes. Req Parameters (a,b,axes)\n",
        "  print(\"Dot product of x29 and x30 is: \",sess.run(x34))\n",
        "  print(\"\")\n",
        "\n",
        "  \n",
        "  x35 = tf.cross(x30,x31)           # Returns the element wise cross product\n",
        "  print(\"Cross product of x30 and x31 is: \", sess.run(x35))\n",
        "  print(\"\")\n",
        "\n",
        "  \n",
        "  x36 = tf.diag([1,2,3,4])          # Returns a matrix with given diagonal value, others set to zero. Req parameter (array of values)\n",
        "  print(\"Matrix (x36) with given diagonal value is:\", sess.run(x36))\n",
        "  print(\"\")\n",
        "  \n",
        "  \n",
        "  x37 = tf.trace(x36)               # Return the sum of the diagonal values. Req Parameters (matrix tensor)\n",
        "  print(\"Sum of diagonal values of x36 is: \", sess.run(x37))\n",
        "  print(\"\")\n",
        "  \n",
        "  \n",
        "  x38 = tf.transpose(x36)           # Switches rows and columns. Req parameters (matrix tensor)\n",
        "  print(\"Transpose of x36 is: \", sess.run(x38))\n",
        "  print(\"\")\n",
        "  \n",
        "  \n",
        "  x39 = tf.matmul(x40,x41,transpose_a=False,transpose_b=False, adjoint_a=False, adjoint_b=False, a_is_sparse=False, b_is_sparse=False)          \n",
        "  # Returns the product of the two input matrices. Req Parameters (a,b)\n",
        "  # Can also calculate matrix multiplications with transposes and adjoints of both matrix\n",
        "  print(\"Matrix Multiplication of x40 and x41 is: \", sess.run(x39))\n",
        "  print(\"\")\n",
        "  \n",
        "  \n",
        "  x42 = tf.cast(x41,tf.float32)\n",
        "  #print(sess.run(x42))\n",
        "  \n",
        "  \n",
        "  x43 = tf.norm(x42,ord=1,axis=0,keep_dims=False)\n",
        "  print(\"Norm of x40\", sess.run(x43))\n",
        "  # tf.norm() returns the norm of the given axis of the input tensor with the specified order. \n",
        "  # ord: Order of the norm. Supported values are 'fro', 'euclidean', 1, 2, np.inf and any positive real number yielding the corresponding p-norm.\n",
        "\n",
        "  ''' \n",
        "  Other Function includes:\n",
        "  * tf.matrix_solve(A,b,adjoint=None,name)                   Returns the tensor x, such that Ax = b, where A is a matrix and b in a vector\n",
        "  * tf.qr(input,full_matrices=None,name)                     Return the eigenvectors and eigenvalues of the given matrix or matrices\n",
        "  * tf.scd(tensor,full_matrices=False,compute_uv=True)       Factors the matrix into a unitary matrix\n",
        "  '''"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dot product of x29 and x30 is:  32\n",
            "\n",
            "Cross product of x30 and x31 is:  [-3  6 -3]\n",
            "\n",
            "Matrix (x36) with given diagonal value is: [[1 0 0 0]\n",
            " [0 2 0 0]\n",
            " [0 0 3 0]\n",
            " [0 0 0 4]]\n",
            "\n",
            "Sum of diagonal values of x36 is:  10\n",
            "\n",
            "Transpose of x36 is:  [[1 0 0 0]\n",
            " [0 2 0 0]\n",
            " [0 0 3 0]\n",
            " [0 0 0 4]]\n",
            "\n",
            "Matrix Multiplication of x40 and x41 is:  [[ 30  24  18]\n",
            " [ 84  69  54]\n",
            " [138 114  90]]\n",
            "\n",
            "Norm of x40 [18. 15. 12.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QeEYLJFRcou",
        "colab_type": "text"
      },
      "source": [
        "## 10) Executing Graphs in Session\n",
        "When an aplication executes a Tensorflow function that creats, transforms or \n",
        "processes a tensor, the function doesn't execute its operations. Instead, \n",
        "it stores its operation in a data structure called a graph. A graph hold many\n",
        "operations, and they're not execute until the application executes the graph in\n",
        "a sessio. When a session executes a graph, it performs the graph's operations \n",
        "in order. \n",
        "The benefit of storing operations in a graph is that the graph can be exported \n",
        "to a file or launched on a remote system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0LEPuS-TOaY",
        "colab_type": "text"
      },
      "source": [
        "## Forming Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS86LvxwTf2u",
        "colab_type": "text"
      },
      "source": [
        "* A graph contains nodes and edges similar to that or normal graph in maths.\n",
        "* Nodes contains the variables or constants and edges represents the relationship between the variables/constants.\n",
        "* Graphs cannot be nested and only one graph can be active at a time.\n",
        "* An application can access its default graph by calling get_default_graph().\n",
        "* An application can create a new graph by calling tf.graph().\n",
        "* The Graph class provides many methods that access and modify the graph's \n",
        "contents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg_gAHr1VO3r",
        "colab_type": "text"
      },
      "source": [
        "### Accessing graph data\n",
        "A graph stores its elements in a set of named collections.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hVSp2EuWpZJ",
        "colab_type": "text"
      },
      "source": [
        "The following represents all the method of Graph class that are use to access \n",
        "and update these collections.\n",
        "* get_tensor_by_name(name):                       \n",
        "Returns the tensor with the given name.\n",
        "\n",
        "* get_operation_by_name(name):                               \n",
        "Returns the operation with the given name\n",
        "\n",
        "* get_operations():                             \n",
        "Returns a list containing the graph's operations\n",
        "\n",
        "* get_all_collection_keys():                                   \n",
        "Returns a list of graph's collection\n",
        "\n",
        "* get_collection(name,scope=None):                             \n",
        "Returns a list of values in the given collection\n",
        "\n",
        "* add_to_collection(name, value):                    \n",
        "Adds the value to the container, can be accessed with name\n",
        "\n",
        "* add_to_collections(name, value):                    \n",
        "Adds the values to the containers, can be accessed with name\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiIm5HyZzyR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.get_default_graph().get_operations())\n",
        "# It literally prints all the operations used across this notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK-BUMSKcxq_",
        "colab_type": "text"
      },
      "source": [
        "### Lets create a new graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL-TpwTxbtpr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e59aa4a5-3f20-4865-e9c5-b22f32fe6b5b"
      },
      "source": [
        "default_graph = tf.get_default_graph() \n",
        "\n",
        "newgraph = tf.Graph()                    \n",
        "# Created new graph named \"newgraph\".\n",
        "\n",
        "# So now we have two graphs, one default graph names \"default_graph\" and one is newly created graph names \"newgraph\". \n",
        "\n",
        "with newgraph.as_default():\n",
        "  x44 = tf.constant([1.1,2.1,3.1], name= \"x44\")       \n",
        "  x45 = tf.constant([1.2,2.2,3.2], name=\"x45\")\n",
        "  x46 = tf.constant([1.3,2.3,3.3], name=\"x46\")\n",
        "# So the tensors created above (x44,x45,x46) will be stored in newgraph as NODES.\n",
        "\n",
        "x47 = tf.constant(55)\n",
        "x48 = tf.constant(45)\n",
        "# And the tensor which is created outsite the scope of newgraph.as_default() will be added to \"default_graph\" as NODES.\n",
        "\n",
        "# We can check which tensor is added to which graph with the help of the following command.\n",
        "print(x44.graph is newgraph)\n",
        "print(x45.graph is newgraph)\n",
        "print(x46.graph is newgraph)\n",
        "\n",
        "print(x47.graph is newgraph)\n",
        "print(x48.graph is newgraph)\n",
        "print(x47.graph is default_graph) \n",
        "print(x48.graph is default_graph) "
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw8nspCJfGC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fcecb59b-5c96-4fe5-c89a-2938631bb1f4"
      },
      "source": [
        "x49 = tf.tensordot(x44,x45,1)\n",
        "tf.identity(x49, name=\"x49\")\n",
        "x50 = tf.add(x47,x48)\n",
        "\n",
        "print(x49.graph is default_graph)      # FALSE\n",
        "print(x49.graph is newgraph)           # TRUE\n",
        "print(\"So x49 is in newgraph\")\n",
        "\n",
        "print(x50.graph is default_graph)      # TRUE\n",
        "print(x50.graph is newgraph)           # FALSE\n",
        "print(\"So x50 is NOT in newgraph, its in default_graph\")\n",
        "# This means tensors created by performing operations with tensors under new graph will be added to that new graph. "
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "So x49 is in newgraph\n",
            "True\n",
            "False\n",
            "So x50 is NOT in newgraph, its in default_graph\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_50kVyAF4hZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "40855cf4-a281-43ec-b212-3d5d39fbcde5"
      },
      "source": [
        "# Examples of get_tensor_by_name()\n",
        "\n",
        "with tf.Session(graph=newgraph) as sess:\n",
        "  test1 = sess.graph.get_operations()\n",
        "# print(test1)\n",
        "  test2 = sess.graph.get_tensor_by_name(\"x44:0\")          # While using the name, add :0\n",
        "  print(test2)\n",
        "  test3 = sess.graph.get_tensor_by_name(\"x45:0\")\n",
        "  print(test3)\n",
        "  print(sess.run(x49))\n",
        "  test4 = sess.graph.get_tensor_by_name(\"x49:0\")\n",
        "  print(test4)\n",
        "  \n",
        "  "
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"x44:0\", shape=(3,), dtype=float32)\n",
            "Tensor(\"x45:0\", shape=(3,), dtype=float32)\n",
            "15.86\n",
            "Tensor(\"x49:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMRJdouuKEW3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c330603d-04ee-4c4e-c8d3-04784dd4d4e2"
      },
      "source": [
        "# Examples of get_operation_by_name(), get_all_collection_keys()\n",
        "\n",
        "\n",
        "newgraph1 = tf.Graph()\n",
        "with tf.Session(graph=newgraph1) as sess:\n",
        "  x51 = tf.constant(55)\n",
        "  x52 = tf.constant(45)\n",
        "  print(x51.graph is newgraph1)\n",
        "  print(x52.graph is newgraph1)\n",
        "  test5 = tf.add(x51,x52,name=\"test5\")\n",
        "  print(sess.run(test5))\n",
        "  print(\"\")\n",
        "  print(sess.graph.get_operation_by_name(\"test5\"))\n",
        "  print(\"\")\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "100\n",
            "\n",
            "name: \"test5\"\n",
            "op: \"Add\"\n",
            "input: \"Const\"\n",
            "input: \"Const_1\"\n",
            "attr {\n",
            "  key: \"T\"\n",
            "  value {\n",
            "    type: DT_INT32\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTl3qg4QR1UK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "adae68a9-96c0-4254-83ba-c12a4f6ad26f"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  print(sess.graph.get_all_collection_keys())\n",
        "#  for op in tf.get_default_graph().get_operations():\n",
        "#    print(str(op.name))\n",
        "# The above code will print all the nodes present in the default graph\n",
        "\n",
        "#with tf.Session(graph=newgraph) as sess:\n",
        "#  for op in sess.graph.get_operations():\n",
        "#    print(str(op.name))\n",
        "\n",
        "# The above code will print all the nodes present in the newgraph"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['trainable_variables', 'variables']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqTqbrbJYzxM",
        "colab_type": "text"
      },
      "source": [
        "### So, we learned the following concepts about the graph in tensorflow:\n",
        "* All the tensors are stored in default graph, which is called by          \n",
        "graph = tf.get_default_graph()\n",
        "* We can create a new graph by the following code              \n",
        " new_graph = tf.Graph()                                      \n",
        "* To store the tensors in the new graph, we use the following code:             with new_graph.as_default()\n",
        "* If we want to run any operations in our new graph created, like add, multiply\n",
        "etc. We need to explicitly define the new graph while calling the session.      \n",
        "with tf.Session(graph=new_graph) as sess:                           \n",
        "Otherwise it will use the default graph. \n",
        "* Executing any graph operations like get_operations() and all will be done as \n",
        "follows.                           \n",
        "sess.graph.get_operations() .. etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_p1dXtgc0wH",
        "colab_type": "text"
      },
      "source": [
        "## 11) Interactive Session\n",
        "Rather than send an entire scripts to an interpreter, many Python developers \n",
        "prefer to write code interactively. In this mode, the interpreter displays \n",
        "feedback as each line is processed.                       \n",
        "To support interactive development, Tensorflow provides the Interactive Session\n",
        "class. It servers the same role as Session, but it makes itself the default \n",
        "session when it's constructed.                             \n",
        "Instead of calling sess.run, you can evaluate tensors by calling their eval\n",
        "method. Similarly, you can execute operations by calling the run method of the \n",
        "Operation Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNyqlmZUUe5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "06c7aabb-7ade-4648-af9e-5b58c47f46fc"
      },
      "source": [
        "x53 = tf.constant(1.2)\n",
        "x54 = tf.constant(3.5)\n",
        "prod = tf.multiply(x53,x54)\n",
        "sess = tf.InteractiveSession()            \n",
        "print(\"Product is: \", prod.eval())"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Product is:  4.2000003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj-OlTF-eyJb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56hmxvfAHC9n",
        "colab_type": "text"
      },
      "source": [
        "# 12) Variables and Placeholders "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43Fa4ul7AtU2",
        "colab_type": "text"
      },
      "source": [
        "### Variables\n",
        "Unlike other Tensorflow objects that are \"refilled\" with data each time we \n",
        "run the session, Variables can maintain a fixed state in the graph. This is \n",
        "important because their current state might influence how they change in the \n",
        "following iteration. Like other Tensors, Variables can be used as input\n",
        "for other operations in the graph.                \n",
        "Using the Variables is done in two stages:                    \n",
        "* First we call the tf.variable() function in order to create a Variable and \n",
        "define what value it will be initialized with.                  \n",
        "* We then have to explicitly perform an initialization operation by running\n",
        "the session with the tf.global_variable_initializer() method, which allocates \n",
        "the memory for the Variable and sets its inital values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZoOEsAhIvbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "42f2bdd1-ccb7-4c0e-df3e-8f4256a2f3d0"
      },
      "source": [
        "# Lets look at an example.\n",
        "\n",
        "x55 = tf.random_normal((1,5),0,1)\n",
        "x56 = tf.Variable(x55, name=\"x56\")                                        # Variable is created and values are defined.\n",
        "print(\"Before initializing the global variable: \\n\", format(x56))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  post_init = sess.run(x56)\n",
        "\n",
        "print(\"\\nAfter initializing the global variable: \\n\", format(post_init))\n"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before initializing the global variable: \n",
            " <tf.Variable 'x56_3:0' shape=(1, 5) dtype=float32_ref>\n",
            "\n",
            "After initializing the global variable: \n",
            " [[ 0.3524621   1.3662233  -1.850988    0.21862166 -0.5396629 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv6xgodwLkB0",
        "colab_type": "text"
      },
      "source": [
        "### Placeholders\n",
        "So far we've used source operations to create our input data. Tensorflow,\n",
        "however has designated built-in structures for feeding input values. These \n",
        "structures are calles placeholders. Placeholders can be thought of as empty \n",
        "Variables that will be filled with data later on. We use them by first \n",
        "constructing our graph and only when it is executed feeding them with the input\n",
        "data.                                         \n",
        "Whenever we define a placeholder, we must feed it with some input values or else an exception will be thrown. The input data is passed to the session.run()\n",
        "method as a dictionary, where each key corresponds to the placeholder variable name, and the matching values are the data values of the placeholder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6H3U1ZMKkfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "986ed6fa-0164-4d95-cb2f-33a0d82dad5c"
      },
      "source": [
        "# Lets see an example of placeholder\n",
        "import numpy as np\n",
        "\n",
        "x57 = np.random.randn(5,10)                        # A random 5x10 matrix is created using numpy\n",
        "x58 = np.random.randn(10,1)                        # A random 10x1 vector is created using numpy\n",
        "\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  x = tf.placeholder(tf.float32,shape=(5,10))      # x is a 5x10 matrix \n",
        "  w = tf.placeholder(tf.float32,shape=(10,1))      # w is 10x1 vector \n",
        "  b = tf.fill((5,1),-1.)                           # b is constant 5x1 vector with all values -1 ie b = [-1,-1,-1,-1,-1]\n",
        "  xw = tf.matmul(x,w)                              # xw is the resultant vector of the matrix multiplication of x and w, shape will be 5x1\n",
        "\n",
        "  xwb = xw + b                                     # vector xw is added to vector b\n",
        "  s = tf.reduce_max(xwb)                           # tf.reduce_max() will return the max value of the vector xwb and store it in s\n",
        "  with tf.Session() as sess:\n",
        "    outs = sess.run(s,feed_dict={x: x57,w: x58})     # Value of x57 is stored in placeholder w and value of x58 is stored in placeholder w\n",
        "\n",
        "print(\"Output = {}\".format(outs))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output = 1.377558708190918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiyDF0WgVRqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}